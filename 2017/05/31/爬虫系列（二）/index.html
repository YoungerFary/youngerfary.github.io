<!DOCTYPE HTML>
<html lang="">
<head><meta name="generator" content="Hexo 3.8.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="Hexo">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <link rel="dns-prefetch" href="http://yoursite.com">
    <!--SEO-->





<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">
    <!--Title-->


<title>爬虫系列（二） | Hexo</title>


    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
		<script type="text/javascript">
			var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan class='cnzz_stat_icon_1263868967 hide' %3E%3Cscript%20src%3D%22https%3A%2F%2Fs95.cnzz.com%2Fz_stat.php%3Fweb_id%3D1272564536%22%3E%3C%2Fscript%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s19.cnzz.com/z_stat.php%3Fid%3D1263868967%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
		</script>
	</div>






    

</head>

</html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header" style="background-image:url(http://snippet.shenliyang.com/img/banner.jpg)">
    <div class="main-header-box">
        <a class="header-avatar" href="/" title="John Doe">
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a>
        <div class="branding">
        	<!--<h2 class="text-hide">Snippet主题,从未如此简单有趣</h2>-->
            
                 <img src="/img/branding.png" alt="Snippet 博客主题" class="img-responsive center-block">
            
    	</div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="navbar-brand" href="http://yoursite.com">Hexo</a>
                </div>
                <div class="collapse navbar-collapse" id="main-menu">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>Home</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/前端/"><i class="fa "></i>前端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/后端/"><i class="fa "></i>后端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/工具/"><i class="fa "></i>工具</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/archives/"><i class="fa "></i>时间轴</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="爬虫系列（二）">
            
	            爬虫系列（二）
            
        </h1>
        <div class="post-meta">
    
    
    <span class="categories-meta fa-wrap">
        <i class="fa fa-folder-open-o"></i>
        <a href="/categories/ ">
             
        </a>
    </span>
    

    
    <span class="fa-wrap">
        <i class="fa fa-tags"></i>
        <span class="tags-meta">
            
                
                    <a href="/tags/python&amp;Scrapy" title="python&amp;Scrapy">
                        python&amp;Scrapy
                    </a>
                
            
        </span>
    </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2017/05/31</span>
        </span>
        
    
</div>

            
            
            <p class="fa fa-exclamation-triangle warning">
                本文于<strong>539</strong>天之前发表，文中内容可能已经过时。
            </p>
        
    </div>
    
    <div class="post-body post-content">
        <p><img src="http://ono5i4nh6.bkt.clouddn.com/%E7%88%AC%E8%99%AB.jpg" alt=""><br>要学好爬虫，当然要先从最基本的开始学，学习她的“套路”，其实以后的东西，都和这个套路差不多，明白套路，实际上手练几个爬虫，多多少少可以应付一些网站的爬取！<br><a id="more"></a><br>首先入门应该从urllib开始学起，虽然到后面我们都不怎么去用，可能是效率偏低，但确是入门的好材料！</p>
<h1 id="一、urllib的基本用法"><a href="#一、urllib的基本用法" class="headerlink" title="一、urllib的基本用法"></a>一、urllib的基本用法</h1><h2 id="1、用urllib去爬取一个网页"><a href="#1、用urllib去爬取一个网页" class="headerlink" title="1、用urllib去爬取一个网页"></a>1、用urllib去爬取一个网页</h2><p>一般的网页上的信息要怎样抓取呢！本质就是根据URL去获取它的网页信息。我们我们在浏览器中看到的是一幅幅优美的画面，其实是由浏览器解释才呈现出来的，实质它是一段HTML代码，加 JS、CSS，如果把网页比作一个人，那么HTML便是他的骨架，JS便是他的肌肉，CSS便是它的衣服。所以最重要的部分是存在于HTML中的，下面我们就写个例子来扒一个网页下来。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line">response = urllib2.urlopen(<span class="string">"http://www.baidu.com"</span>)</span><br><span class="line">print response.read()</span><br></pre></td></tr></table></figure></p>
<p>是的你没看错，真正的程序就两行，把它保存成 demo.py，进入该文件的目录，执行如下命令查看运行结果:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python demo.py</span><br></pre></td></tr></table></figure></p>
<p>这里我们可以看到网页都被扒下来了，这里的pyhton版本是python2.7,3以上的教程也有了，可以去搜搜看。<br>！<a href="http://ono5i4nh6.bkt.clouddn.com/baidu%E7%88%AC%E5%8F%96%E6%88%AA%E5%9B%BE.png" target="_blank" rel="noopener">baidujietu</a><br>看吧，这些输出的东西就是我们刚刚爬取下来的东西！</p>
<h2 id="2、我们来分析分析"><a href="#2、我们来分析分析" class="headerlink" title="2、我们来分析分析"></a>2、我们来分析分析</h2><p>首先第一行：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response = urllib2.urlopen(<span class="string">"http://www.baidu.com"</span>)</span><br></pre></td></tr></table></figure></p>
<p>urlopen是urllib2库里面的方法，传入一个URL，这个网址是百度，首页协议是HTTP协议，当然你也可以把HTTP换做FTP,FILE,HTTPS 等等，只是代表了一种访问控制协议，urlopen一般接受三个参数，它的参数如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urlopen(url, data, timeout)</span><br></pre></td></tr></table></figure></p>
<p>第一个参数url即为URL，第二个参数data是访问URL时要传送的数据，第三个timeout是设置超时时间。第二三个参数是可以不传送的，data默认为空None，timeout默认为 socket._GLOBAL_DEFAULT_TIMEOUT,第一个参数URL是必须要传送的，在这个例子里面我们传送了百度的URL，执行urlopen方法之后，返回一个response对象，返回信息便保存在这里面。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print response.read()</span><br></pre></td></tr></table></figure></p>
<p>这时候我们就可以看到返回的就是这个网站的实体！这里注意一定要打read()哦，不然只会打出一串字符串！</p>
<h2 id="3、用Request"><a href="#3、用Request" class="headerlink" title="3、用Request"></a>3、用Request</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line">request = urllib2.Request(<span class="string">"http://www.baidu.com"</span>)</span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line">print response.read()</span><br></pre></td></tr></table></figure>
<p>这里我们可以用类似java的封装思想去弄，这样就逻辑比较清晰，推荐大家这么写，打出来的结果还是一样的</p>
<h2 id="4、数据传送两种方式：POST和GET"><a href="#4、数据传送两种方式：POST和GET" class="headerlink" title="4、数据传送两种方式：POST和GET"></a>4、数据传送两种方式：POST和GET</h2><p>以上的基本方式实现的是少数基本网页的抓取，不过现在大多数网站都是动态网页，需要你动态地传递参数给它，它做出对应的响应，例如是登录注册的时候！<br>数据传送分为POST和GET两种方式，两种方式有什么区别呢？<br>最重要的区别是GET方式是直接以链接形式访问，链接中包含了所有的参数，当然如果包含了密码的话是一种不安全的选择，不过你可以直观地看到自己提交了什么内容。POST则不会在网址上显示所有的参数，不过如果你想直接查看提交了什么就不太方便了。（例如有些网站用的get,那么你就可以看到你提交了一些什么样的参数）</p>
<h4 id="1-用post方法去实现网页登陆："><a href="#1-用post方法去实现网页登陆：" class="headerlink" title="(1)用post方法去实现网页登陆："></a>(1)用post方法去实现网页登陆：</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line">values = &#123;<span class="string">"username"</span>:<span class="string">"******@qq.com"</span>,<span class="string">"password"</span>:<span class="string">"XXXX"</span>&#125;</span><br><span class="line">data = urllib.urlencode(values)</span><br><span class="line">url = <span class="string">"https://passport.csdn.net/account/login?from=http://my.csdn.net/my/mycsdn"</span></span><br><span class="line">request = urllib2.Request(url,data)</span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line">print response.read()</span><br></pre></td></tr></table></figure>
<p>就是说在这传递的data 参数是username和password,不过记得要编码！这里是隐式的一个传送，是可以不再页面中显示出来的</p>
<h4 id="2-GET方式："><a href="#2-GET方式：" class="headerlink" title="(2)GET方式："></a>(2)GET方式：</h4><p>至于GET方式我们可以直接把参数写到网址上面，直接构建一个带参数的URL出来即可。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line">values=&#123;&#125;</span><br><span class="line">values[<span class="string">'username'</span>] = <span class="string">"1016903103@qq.com"</span></span><br><span class="line">values[<span class="string">'password'</span>]=<span class="string">"XXXX"</span></span><br><span class="line">data = urllib.urlencode(values)</span><br><span class="line">url = <span class="string">"http://passport.csdn.net/account/login"</span></span><br><span class="line">geturl = url + <span class="string">"?"</span>+data</span><br><span class="line">request = urllib2.Request(geturl)</span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line">print response.read()</span><br></pre></td></tr></table></figure></p>
<p>例如这样，他把这些数据加到了url后面，然后用？去分割！和我们平常GET访问方式一模一样，这样就实现了数据的GET方式传送</p>
<h1 id="二、urllib的一些高级用法"><a href="#二、urllib的一些高级用法" class="headerlink" title="二、urllib的一些高级用法"></a>二、urllib的一些高级用法</h1><h2 id="1、设置Headers"><a href="#1、设置Headers" class="headerlink" title="1、设置Headers"></a>1、设置Headers</h2><p>如果程序直接用上面的方式进行访问，有些网站不会同意，如果识别有问题，那么站点根本不会响应，所以为了完全模拟浏览器的工作，我们需要设置一些Headers 的属性。<br>我们来看看知乎的例子吧：<br><img src="http://ono5i4nh6.bkt.clouddn.com/%E7%9F%A5%E4%B9%8E.png" alt="知乎页面分析"><br>右键检查，network，选中，就可以看到这些信息！这些内容也不是一次性就加载完成的，实质上是执行了好多次请求，一般是首先请求HTML文件，然后加载JS，CSS 等等，经过多次请求之后，网页的骨架和肌肉全了，整个网页的效果也就出来了。<br>我们看看这些请求，有个Request URL，还有headers，下面便是response，agent就是请求的身份，如果没有写入请求身份，那么服务器不一定会响应，所以可以在headers中设置agent,例如下面的例子，这个例子只是说明了怎样设置的headers，了解一下设置格式就好。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib  </span><br><span class="line"><span class="keyword">import</span> urllib2  </span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://www.server.com/login'</span></span><br><span class="line">user_agent = <span class="string">'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'</span>  </span><br><span class="line">values = &#123;<span class="string">'username'</span> : <span class="string">'cqc'</span>,  <span class="string">'password'</span> : <span class="string">'XXXX'</span> &#125;  </span><br><span class="line">headers = &#123; <span class="string">'User-Agent'</span> : user_agent &#125;  </span><br><span class="line">data = urllib.urlencode(values)  </span><br><span class="line">request = urllib2.Request(url, data, headers)  </span><br><span class="line">response = urllib2.urlopen(request)  </span><br><span class="line">page = response.read()</span><br></pre></td></tr></table></figure></p>
<p>这样，我们设置了一个headers，在headers中去设置agent,在构建request时传入，在请求时，就加入了headers传送，这样就会假装是浏览器去访问。<br>另外，我们还有对付”反盗链”的方式，对付防盗链，服务器会识别headers中的referer是不是它自己，如果不是，有的服务器不会响应，所以我们还可以在headers中加入referer，例如我们可以构建下面的headers<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123; <span class="string">'User-Agent'</span> : <span class="string">'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'</span>  ,</span><br><span class="line">                        <span class="string">'Referer'</span>:<span class="string">'http://www.zhihu.com/articles'</span> &#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="2、-Proxy（代理）的设置"><a href="#2、-Proxy（代理）的设置" class="headerlink" title="2、 Proxy（代理）的设置"></a>2、 Proxy（代理）的设置</h2><p>假如一个网站它会检测某一段时间某个IP 的访问次数，如果访问次数过多，它会禁止你的访问。所以你可以设置一些代理服务器来帮助你做工作，每隔一段时间换一个代理，网站不知道是谁在访问，这样就会认为是正常访问！上上篇有篇博客就有讲这个ip代理问题！<br>面一段代码说明了代理的设置用法：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line">enable_proxy = True</span><br><span class="line">proxy_handler = urllib2.ProxyHandler(&#123;<span class="string">"http"</span> : <span class="string">'http://some-proxy.com:8080'</span>&#125;)</span><br><span class="line">null_proxy_handler = urllib2.ProxyHandler(&#123;&#125;)</span><br><span class="line"><span class="keyword">if</span> enable_proxy:</span><br><span class="line">    opener = urllib2.build_opener(proxy_handler)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    opener = urllib2.build_opener(null_proxy_handler)</span><br><span class="line">urllib2.install_opener(opener)</span><br></pre></td></tr></table></figure></p>
<h2 id="3、Timeout-设置"><a href="#3、Timeout-设置" class="headerlink" title="3、Timeout 设置"></a>3、Timeout 设置</h2><p>为了解决一些网站实在响应过慢而造成的影响。通过设置urlopen方法，第三个参数就是timeout的设置<br>例如：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line">response = urllib2.urlopen(<span class="string">'http://www.baidu.com'</span>, timeout=<span class="number">10</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="4、使用-HTTP-的-PUT-和-DELETE-方法"><a href="#4、使用-HTTP-的-PUT-和-DELETE-方法" class="headerlink" title="4、使用 HTTP 的 PUT 和 DELETE 方法"></a>4、使用 HTTP 的 PUT 和 DELETE 方法</h2><p>http协议有六种请求方法，get,head,put,delete,post,options，下面讲讲put和post区别<br>PUT：这个方法比较少见。HTML表单也不支持这个。本质上来讲， PUT和POST极为相似，都是向服务器发送数据，但它们之间有一个重要区别，PUT通常指定了资源的存放位置，而POST则没有，POST的数据存放位置由服务器自己决定。<br>DELETE：删除某一个资源。基本上这个也很少见，不过还是有一些地方比如amazon的S3云服务里面就用的这个方法来删除资源。</p>
<h2 id="5-使用DebugLog"><a href="#5-使用DebugLog" class="headerlink" title="5.使用DebugLog"></a>5.使用DebugLog</h2><p>可以通过下面的方法把 Debug Log 打开，这样收发包的内容就会在屏幕上打印出来，方便调试!<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line">httpHandler = urllib2.HTTPHandler(debuglevel=<span class="number">1</span>)</span><br><span class="line">httpsHandler = urllib2.HTTPSHandler(debuglevel=<span class="number">1</span>)</span><br><span class="line">opener = urllib2.build_opener(httpHandler, httpsHandler)</span><br><span class="line">urllib2.install_opener(opener)</span><br><span class="line">response = urllib2.urlopen(<span class="string">'http://www.baidu.com'</span>)</span><br></pre></td></tr></table></figure></p>
<p>基本就这么多了，下面还有cookie使用和正则，慢慢学习吧！</p>
<p>多走路，多思考，越努力，越幸运！<br>                                                                                                                            ———————————————YoungerFary</p>

    </div>
    
        <div class="reward">
    <div class="reward-wrap">赏
        <div class="reward-box">
            
            
                <span class="reward-type">
                    <img class="wechat" src="../img/reward-wepay.jpg"><b>微信打赏</b>
                </span>
            
        </div>
    </div>
    <p class="reward-tip">赞赏是不耍流氓的鼓励</p>
</div>


    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="" target="_blank">Snippet</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/2017/06/02/爬虫系列（三）/" class="pre-post btn btn-default" title="爬虫系列（三）">
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">爬虫系列（三）</span>
        </a>
    
    
        <a href="/2017/05/29/爬虫系列（一）/" class="next-post btn btn-default" title="爬虫系列（一）">
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">爬虫系列（一）</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
    
    <div id="vcomments" class="valine"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>

    <script>
        new Valine({
            av: AV,
            el: '#vcomments',
            appId: 'xOKV9J4UeQAtVkvnJC7Kq2Jn-gzGzoHsz',
            appKey: 'erIpQac4azoCmgfBB7Dl9maa',
            placeholder: '说点什么吧',
            notify: false,
            verify: false,
            avatar: 'mm',
            meta: 'nick,mail'.split(','),
            pageSize: '10',
            path: window.location.pathname,
            lang: ''.toLowerCase()
        })
    </script>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">Table of Contents</h3>
        
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#一、urllib的基本用法"><span class="toc-text">一、urllib的基本用法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1、用urllib去爬取一个网页"><span class="toc-text">1、用urllib去爬取一个网页</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2、我们来分析分析"><span class="toc-text">2、我们来分析分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3、用Request"><span class="toc-text">3、用Request</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4、数据传送两种方式：POST和GET"><span class="toc-text">4、数据传送两种方式：POST和GET</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-用post方法去实现网页登陆："><span class="toc-text">(1)用post方法去实现网页登陆：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-GET方式："><span class="toc-text">(2)GET方式：</span></a></li></ol></li></ol></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#二、urllib的一些高级用法"><span class="toc-text">二、urllib的一些高级用法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1、设置Headers"><span class="toc-text">1、设置Headers</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2、-Proxy（代理）的设置"><span class="toc-text">2、 Proxy（代理）的设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3、Timeout-设置"><span class="toc-text">3、Timeout 设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4、使用-HTTP-的-PUT-和-DELETE-方法"><span class="toc-text">4、使用 HTTP 的 PUT 和 DELETE 方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-使用DebugLog"><span class="toc-text">5.使用DebugLog</span></a></li></ol></li>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2017
                </span> |
                <span>
                    Powered by <a href="//hexo.io" class="copyright-links" target="_blank" rel="nofollow">Hexo</a>
                </span> |
                <span>
                    Theme by <a href="//github.com/shenliyang/hexo-theme-snippet.git" class="copyright-links" target="_blank" rel="nofollow">Snippet</a>
                </span>
            </div>
        </div>
    </div>
</div>







<script src="/js/app.js?rev=@@hash"></script>

</body>
</html>